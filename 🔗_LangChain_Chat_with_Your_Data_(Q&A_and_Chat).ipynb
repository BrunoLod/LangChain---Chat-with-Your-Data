{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ApresentaÃ§Ã£o âœ’ï¸\n",
        "\n",
        "Notebook referente ao curso de LangChain disponibilizado na plataforma DeepLearningAI. Essa parte Ã© uma finalizaÃ§Ã£o do curso como um todo, o qual passou pela etapa de carregamento de dados, divisÃ£o da informaÃ§Ã£o (pois se trata de um processo de otimizaÃ§Ã£o e reduÃ§Ã£o de custos de processamento para dados de elevada quantidade) e criaÃ§Ã£o de banco de dados vetoriais, nos quais armazena-se o conteÃºdo.\n",
        "\n",
        "O objetivo agora Ã© conseguir desenvolver um chat de perguntas e respostas e outro que consiga desempenhar a mesma relaÃ§Ã£o, mas apresentando memÃ³ria, como forma de otimizar o processo de interaÃ§Ã£o com o usuÃ¡rio. Assim, a partir de uma pergunta busca-se prover ao usuÃ¡rio um retorno relacionado a essa, bem como uma vez fornecida ficar na \"memÃ³ria\" do modelo de LLM de uso, para que ele nÃ£o precise realizar a consulta novamente."
      ],
      "metadata": {
        "id": "DznNFxAAJxsQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bibliotecas ğŸ“š"
      ],
      "metadata": {
        "id": "AH7Y9vJaJssI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K2oXlggR9rj-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ab516e3-03cd-4cd6-9806-a8a65199530a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m975.5/975.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m337.4/337.4 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m163.9/163.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m718.3/718.3 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m270.2/270.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m559.5/559.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade langchain -q\n",
        "\n",
        "!pip install --upgrade langchain_community -q\n",
        "\n",
        "!pip install google-generativeai -q\n",
        "\n",
        "!pip install langchain_google_genai -q\n",
        "\n",
        "!pip install docarray -q\n",
        "\n",
        "!pip install pypdf -q\n",
        "\n",
        "!pip install chromadb -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "sys.path.append('../..')\n",
        "import google.generativeai as genai\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.vectorstores import DocArrayInMemorySearch\n",
        "from langchain.embeddings import GooglePalmEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "HqALS6WAEIQM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definindo as variÃ¡veis de ambiente"
      ],
      "metadata": {
        "id": "8ro2-ip-K3zZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo as variÃ¡veis de ambiente.\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"sua-api-key\"\n",
        "\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
      ],
      "metadata": {
        "id": "K8BeFuIZFTIk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instanciando os modelos de uso"
      ],
      "metadata": {
        "id": "AgRB83rcK7Vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciando o modelo de embedding e de LLM de uso.\n",
        "\n",
        "embedding = GooglePalmEmbeddings()\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-1.5-pro-latest\",\n",
        "    temperature = 0.5\n",
        ")"
      ],
      "metadata": {
        "id": "Ejh0v7mkFLcD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregando os dados"
      ],
      "metadata": {
        "id": "4KEwz5cOK_Pw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando os dados que serÃ£o utilizados.\n",
        "\n",
        "loaders = [\n",
        "    PyPDFLoader(\"https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf\"),\n",
        "    PyPDFLoader(\"https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture02.pdf\"),\n",
        "    PyPDFLoader(\"https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture03.pdf\")\n",
        "]"
      ],
      "metadata": {
        "id": "-Ks1aB9lF6HJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando uma lista de documentos PDFs\n",
        "\n",
        "# MÃ©todo extend adiciona cada documento separadamente na lista pdf_docs.\n",
        "\n",
        "pdf_docs = []\n",
        "\n",
        "for loader in loaders:\n",
        "  pdf_docs.extend(loader.load())"
      ],
      "metadata": {
        "id": "sBno6kUyGTP6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantidade de pÃ¡ginas dos arquivos carregados.\n",
        "\n",
        "len(pdf_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOtKZZtEGXtT",
        "outputId": "dd8a48dd-b95b-4965-b0ba-ef6f7a94069f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Realizando a divisÃ£o do conteÃºdo em menores porÃ§Ãµes"
      ],
      "metadata": {
        "id": "pUM89giaLD0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividindo os textos em pequenas porÃ§Ãµes, como forma de otimizar a manipulaÃ§Ã£o\n",
        "# da informaÃ§Ã£o e, principalmente, a recuperaÃ§Ã£o dessa.\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 2000,\n",
        "    chunk_overlap = 200,\n",
        "    length_function = len,\n",
        "    separators = [\"\\n\\n\", \"\\n\", \".\"]\n",
        ")"
      ],
      "metadata": {
        "id": "yk40swX6GiEo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_docs_split = text_splitter.split_documents(pdf_docs)"
      ],
      "metadata": {
        "id": "NAF6E9uTHf7_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Observa-se que a quantidade de itens alterou apÃ³s a divisÃ£o, duplicando\n",
        "# em relaÃ§Ã£o ao valor original.\n",
        "\n",
        "print(f'Quantidade de itens antes da divisÃ£o : {len(pdf_docs)}')\n",
        "print(f'Quantidade de itens apÃ³s a divisÃ£o : {len(pdf_docs_split)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3pLGGKVHouI",
        "outputId": "87e789c2-12f6-4125-e6e9-b5e4a6731650"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de itens antes da divisÃ£o : 56\n",
            "Quantidade de itens apÃ³s a divisÃ£o : 108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criando o banco de dados vetorial com Chroma"
      ],
      "metadata": {
        "id": "y4YAGhjqLJlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando o vector databse :\n",
        "\n",
        "persist_directory = 'docs/chroma/'"
      ],
      "metadata": {
        "id": "bVFZOXXgHUrd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./docs/chroma  # Remove datavase antigo se existe."
      ],
      "metadata": {
        "id": "0Axq7oP6HcA8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciando o vector databse com Chroma, um framework open source\n",
        "# que cria banco de dados vetoriais, bastando informar principalmente\n",
        "# a informaÃ§Ã£o que deseja ser armazenada e o modelo de embedding utilizado\n",
        "# para a sua transformaÃ§Ã£o vetorial.\n",
        "\n",
        "docs_vectordb = Chroma.from_documents(\n",
        "    documents=pdf_docs_split,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ],
      "metadata": {
        "id": "bJH1SiKHHdoS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verificando se o conteÃºdo foi armazenado no banco de dados.\n",
        "\n",
        "docs_vectordb._collection.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNm-9BkCIHyJ",
        "outputId": "87a64756-578d-427a-b4a6-33f487b0e85b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "108"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criando a RetrievalQAChain"
      ],
      "metadata": {
        "id": "n-aiIizaLOPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "RPaPZF1TJVkJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"refine\",\n",
        "    retriever=docs_vectordb.as_retriever()\n",
        ")"
      ],
      "metadata": {
        "id": "sOLuue3-LgG6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Consultando a qa_chain :\n",
        "\n",
        "question = \"What are the major topics for this class?\"\n",
        "\n",
        "result = qa_chain({\"query\": question})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "ugj1N4bQQL4i",
        "outputId": "4b38ed6b-569d-4ba1-f638-396bbde10185"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "J5Kax2FhQfRq",
        "outputId": "4f0ac261-c8d0-45d6-d756-a2955ed216d8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The new context provides additional clues about the course content, allowing us to refine the initial answer. \\n\\n**Refined Major Topics:**\\n\\n* **Machine Learning:** Confirmed as the core focus.\\n* **Linear Regression:**  Specifically mentioned as a major topic.\\n* **Gradient Descent:**  A key optimization algorithm used in machine learning, covered in detail.\\n* **Normal Equations:**  An alternative approach to solving linear regression problems.\\n* **Linear Algebra:**  Fundamental to the course, with a dedicated review session. \\n* **Convex Optimization:** Likely to be important given the focus on gradient descent (a convex optimization algorithm). \\n* **Programming:**  While not explicitly mentioned, practical application is implied through assignments.\\n\\n**Removed/Uncertain Topics:**\\n\\n* **Hidden Markov Models:**  No longer mentioned, so their inclusion is uncertain. \\n\\n**Overall:**\\n\\nThe new context confirms and expands upon our initial understanding. The course heavily emphasizes **linear regression** as a starting point, delving into both theoretical aspects (normal equations) and practical implementation (gradient descent).  **Linear algebra** is essential for understanding these concepts.  \\n\\nThe mention of assignments reinforces the practical nature of the course, suggesting programming will be involved. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_2 = \"In this class talking about neural networks ?\"\n",
        "\n",
        "result_2 = qa_chain({\"query\": question_2})"
      ],
      "metadata": {
        "id": "SHN6L9MnQkHC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55pkiH8-RSry",
        "outputId": "ba4c128b-9f04-447f-f2c2-b3466e646d55"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'In this class talking about neural networks ?',\n",
              " 'result': 'The new context, while providing information about the course structure and MATLAB, **doesn\\'t offer any further clues about whether neural networks will be specifically covered.** \\n\\nThe excerpt focuses on:\\n\\n* **Student feedback:**  The anecdote about MATLAB highlights its usefulness but doesn\\'t reveal anything about the course content itself.\\n* **Discussion section purpose:** The description emphasizes reviewing prerequisites (probability, statistics, algebra) and covering potential extensions to the main lecture material. \\n\\nSince neural networks aren\\'t mentioned in either context, we can\\'t definitively say if they are part of the curriculum.  The original answer still stands: it\\'s possible neural networks are included, especially given the emphasis on \"state-of-the-art\" algorithms, but we don\\'t have enough information to be certain. \\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combinando RetrievalQ&A com PromptTemplate\n",
        "\n",
        "Essa tÃ©cnica serve como ajuste Ã  LLM fornecer respostas mais apuradas e estruturadas, como forma de melhorar a experiÃªncia do usuÃ¡rio."
      ],
      "metadata": {
        "id": "MPsA0aKTRvL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate"
      ],
      "metadata": {
        "id": "_6FhjFz-RYA6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Use the following pieces of {context} to answer the question at the end.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Helpful Answer:\n",
        "\"\"\"\n",
        "\n",
        "qa_prompt_template = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "EhjddchpZJOz"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain_template = RetrievalQA.from_chain_type(\n",
        "    llm = llm,\n",
        "    chain_type = \"stuff\",\n",
        "    retriever = docs_vectordb.as_retriever(),\n",
        "    return_source_documents = True, # Retorna a fonte da resposta.\n",
        "    chain_type_kwargs = {\"prompt\": qa_prompt_template}\n",
        ")"
      ],
      "metadata": {
        "id": "o9UaPFGqZhuC"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_3 = \"In this class talking about machine learning ?\"\n",
        "\n",
        "result_3 = qa_chain_template({\"query\": question_3})"
      ],
      "metadata": {
        "id": "FfBjNyrzZ8z-"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Af5AQrEbD16",
        "outputId": "f317e82e-b18e-4bb1-f060-dd9e1aee4b5d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'In this class talking about machine learning ?',\n",
              " 'result': 'The transcript provided is from a machine learning class, and the instructor explicitly states he will be talking about machine learning. So the answer is yes. \\n',\n",
              " 'source_documents': [Document(metadata={'page': 0, 'source': 'https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf'}, page_content=\"MachineLearning-Lecture01  \\nInstructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machine \\nlearning class. So what I wanna do today is ju st spend a little time going over the logistics \\nof the class, and then we'll start to  talk a bit about machine learning.  \\nBy way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class. And so \\nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \\nI actually think that machine learning is th e most exciting field of all the computer \\nsciences. So I'm actually always excited about  teaching this class. Sometimes I actually \\nthink that machine learning is not only the most exciting thin g in computer science, but \\nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \\nI also want to introduce the TAs, who are all graduate students doing research in or \\nrelated to the machine learni ng and all aspects of machin e learning. Paul Baumstarck \\nworks in machine learning and computer vision.  Catie Chang is actually a neuroscientist \\nwho applies machine learning algorithms to try to understand the human brain. Tom Do \\nis another PhD student, works in computa tional biology and in sort of the basic \\nfundamentals of human learning. Zico Kolter is  the head TA â€” he's head TA two years \\nin a row now â€” works in machine learning a nd applies them to a bunch of robots. And \\nDaniel Ramage is â€” I guess he's not here  â€” Daniel applies l earning algorithms to \\nproblems in natural language processing.  \\nSo you'll get to know the TAs and me much be tter throughout this quarter, but just from \\nthe sorts of things the TA's do, I hope you can  already tell that machine learning is a \\nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \\nin computer vision and biology and robots a nd language. And machine learning is one of \\nthose things that has and is having a large impact on many applications.\"),\n",
              "  Document(metadata={'page': 3, 'source': 'https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf'}, page_content=\"some of my own excitement a bout machine learning to you.  \\nThe second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\\nthe-art machine learning algorithms to whatev er problems you're interested in. And if you \\never need to build a system for reading zi p codes, you'll know how to do that by the end \\nof this class.  \\nAnd lastly, by the end of this class, I reali ze that only a subset of  you are interested in \\ndoing research in machine learning, but by the c onclusion of this class,  I hope that all of \\nyou will actually be well qualified to star t doing research in machine learning, okay?  \\nSo let's say a few words about logistics. The prerequisites of this class are written on one \\nof the handouts, are as follows: In this class, I'm going to assume that all of you have sort \\nof basic knowledge of computer science and kn owledge of the basic computer skills and \\nprinciples. So I assume all of you know what big?O notation, that all of you know about \\nsort of data structures like  queues, stacks, binary trees , and that all of you know enough \\nprogramming skills to, like, write a simple co mputer program. And it turns out that most\"),\n",
              "  Document(metadata={'page': 6, 'source': 'https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf'}, page_content=\"project. So part of the goal of this cla ss is to leave you well eq uipped to apply machine \\nlearning algorithms to a problem or to do rese arch in machine learning. And so as part of \\nthis class, I'll ask you to execute a small resear ch project sort of as a small term project.  \\nAnd what most students do for this is either  apply machine learning to a problem that you \\nfind interesting or investigate some aspect of  machine learning. So to those of you that \\nare either already doing research or to those of you who are in industry, you're taking this \\nfrom a company, one fantastic sort of way to do a class project would be if you apply \\nmachine learning algorithms to a problem that  you're interested in, to a problem that \\nyou're already working on, whether it be a scien ce research problem or sort of a problem \\nin industry where you're trying to get a syst em to work using a learning algorithm.  \\nTo those of you that are not currently doing re search, one great way to do a project would \\nbe if you apply learning algorithms to just pick a problem that you care about. Pick a \\nproblem that you find interesting, and apply lear ning algorithms to that  and play with the \\nideas and see what happens.\"),\n",
              "  Document(metadata={'page': 10, 'source': 'https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf'}, page_content=\"joys of machine learning firs thand and really try to think about doing a publishable piece \\nof work.  \\nSo many students will try to build a cool machine learning application. That's probably \\nthe most common project. Some students will try to improve state-of-the-art machine \\nlearning. Some of those projects are also very  successful. It's a littl e bit harder to do. And \\nthere's also a smaller minority of students th at will sometimes try to prove â€” develop the \\ntheory of machine learning further or try to  prove theorems about machine learning. So \\nthey're usually great projects of all of those types with applications and machine learning \\nbeing the most common. Anything else? Okay, cool.  \\nSo that was it for logistics. Let's talk about  learning algorithms. So can I have the laptop \\ndisplay, please, or the projector? Actually, co uld you lower the big sc reen? Cool. This is \\namazing customer service. Thank you. I see. Okay, cool. Okay. No, that's fine. I see. \\nOkay. That's cool. Thanks. Okay.  \\nBig screen isn't working toda y, but I hope you can read things  on the smaller screens out \\nthere. Actually, [inaudible] I think this room just got a new projector that â€” someone \\nsent you an excited email â€” was it just on Frid ay? â€” saying we just got a new projector \\nand they said 4,000-to-1 something or othe r brightness ratio. I don't know. Someone was \\nvery excited about the new projector in this room, but I guess we'll see that in operation \\non Wednesday.  \\nSo start by talking about what machine learni ng is. What is machine learning? Actually, \\ncan you read the text out there? Raise your hand if the text on the small screens is legible. \\nOh, okay, cool, mostly legible. Okay. So I'll just read it out.  \\nSo what is machine learning? Way back in  about 1959, Arthur Samuel defined machine \\nlearning informally as the [inaudible] that gives computers to learn â€” [inaudible] that \\ngives computers the ability to learn without  being explicitly programmed. So Arthur\")]}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Para verificar a saÃ­da gerada sem o retorno da fonte da resposta.\n",
        "\n",
        "qa_chain_template = RetrievalQA.from_chain_type(\n",
        "    llm = llm,\n",
        "    chain_type = \"stuff\",\n",
        "    retriever = docs_vectordb.as_retriever(),\n",
        "    return_source_documents = False,\n",
        "    chain_type_kwargs = {\"prompt\": qa_prompt_template}\n",
        ")"
      ],
      "metadata": {
        "id": "2ankvXYtbHk0"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_3 = \"In this class talking about machine learning ?\"\n",
        "\n",
        "result_3 = qa_chain_template({\"query\": question_3})"
      ],
      "metadata": {
        "id": "fFmjZT8BgfXU"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wylUzJMDgi-q",
        "outputId": "12f2fe95-4e54-404d-a313-5e8e05cedebb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'In this class talking about machine learning ?',\n",
              " 'result': 'Helpful Answer: Yes, the class is about machine learning. \\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criando um chat"
      ],
      "metadata": {
        "id": "kdQUqIupiShB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True\n",
        ")"
      ],
      "metadata": {
        "id": "q2L5Wj_kgk5q"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "retriever=docs_vectordb.as_retriever()\n",
        "\n",
        "qa = ConversationalRetrievalChain.from_llm(\n",
        "    llm,\n",
        "    retriever=retriever,\n",
        "    memory=memory\n",
        ")"
      ],
      "metadata": {
        "id": "X92NQV7KiYn7"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Is probability a class topic?\"\n",
        "result = qa({\"question\": question})"
      ],
      "metadata": {
        "id": "n_AQSNGGik17"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CaOdjk4im1L",
        "outputId": "5f2bb096-a036-46ee-e31f-15ae6b330c0c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Is probability a class topic?',\n",
              " 'chat_history': [HumanMessage(content='Is probability a class topic?'),\n",
              "  AIMessage(content=\"Yes, probability is a class topic. The instructor mentions that the discussion sections will cover prerequisites like probability, especially for students who haven't encountered it recently or need a refresher. \\n\")],\n",
              " 'answer': \"Yes, probability is a class topic. The instructor mentions that the discussion sections will cover prerequisites like probability, especially for students who haven't encountered it recently or need a refresher. \\n\"}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"why are those prerequesites needed?\"\n",
        "result = qa({\"question\": question})"
      ],
      "metadata": {
        "id": "YRC3gdPDiozT"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atXU-QXJitgj",
        "outputId": "8c8b8ea8-a3c3-478c-f2a7-d3834b8319af"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'why are those prerequesites needed?',\n",
              " 'chat_history': [HumanMessage(content='Is probability a class topic?'),\n",
              "  AIMessage(content=\"Yes, probability is a class topic. The instructor mentions that the discussion sections will cover prerequisites like probability, especially for students who haven't encountered it recently or need a refresher. \\n\"),\n",
              "  HumanMessage(content='why are those prerequesites needed?'),\n",
              "  AIMessage(content='The instructor states that a basic understanding of probability and statistics is needed because students will need to know things like \"what random variables are\", \"what expectation is\", and \"what a variance of a random variable is\". \\n')],\n",
              " 'answer': 'The instructor states that a basic understanding of probability and statistics is needed because students will need to know things like \"what random variables are\", \"what expectation is\", and \"what a variance of a random variable is\". \\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EZGagNH0ivZb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}